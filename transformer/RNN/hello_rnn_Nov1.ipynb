{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100, Total Loss: 9.730\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.148 0.16  0.096 0.595]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.657 0.122 0.211 0.011]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.002 0.826 0.049 0.123]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.002 0.912 0.037 0.05 ]\n",
      "\n",
      "Epoch 2/100, Total Loss: 9.417\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.148 0.168 0.096 0.587]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.642 0.133 0.214 0.011]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.002 0.81  0.051 0.136]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.002 0.898 0.04  0.06 ]\n",
      "\n",
      "Epoch 3/100, Total Loss: 9.109\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.148 0.176 0.096 0.579]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.627 0.144 0.217 0.012]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.002 0.793 0.054 0.15 ]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.002 0.881 0.044 0.072]\n",
      "\n",
      "Epoch 4/100, Total Loss: 8.808\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.149 0.184 0.096 0.571]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.612 0.156 0.22  0.013]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.002 0.775 0.057 0.165]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.002 0.862 0.048 0.087]\n",
      "\n",
      "Epoch 5/100, Total Loss: 8.514\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.149 0.192 0.096 0.562]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.597 0.168 0.222 0.014]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.002 0.757 0.06  0.181]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.003 0.841 0.052 0.104]\n",
      "\n",
      "Epoch 6/100, Total Loss: 8.227\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.15  0.2   0.096 0.553]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.582 0.18  0.223 0.014]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.002 0.737 0.063 0.197]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.003 0.817 0.056 0.124]\n",
      "\n",
      "Epoch 7/100, Total Loss: 7.951\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.151 0.208 0.096 0.544]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.568 0.192 0.225 0.015]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.717 0.067 0.213]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.003 0.79  0.06  0.146]\n",
      "\n",
      "Epoch 8/100, Total Loss: 7.688\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.153 0.216 0.096 0.535]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.554 0.204 0.226 0.016]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.697 0.071 0.23 ]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.004 0.762 0.064 0.17 ]\n",
      "\n",
      "Epoch 9/100, Total Loss: 7.437\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.154 0.224 0.096 0.526]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.541 0.216 0.227 0.016]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.677 0.075 0.246]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.004 0.731 0.067 0.197]\n",
      "\n",
      "Epoch 10/100, Total Loss: 7.197\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.156 0.232 0.096 0.516]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.528 0.227 0.228 0.017]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.657 0.079 0.262]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.005 0.699 0.07  0.226]\n",
      "\n",
      "Epoch 11/100, Total Loss: 6.965\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.158 0.24  0.097 0.506]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.515 0.238 0.229 0.018]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.637 0.083 0.277]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.006 0.664 0.072 0.258]\n",
      "\n",
      "Epoch 12/100, Total Loss: 6.742\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.16  0.248 0.097 0.496]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.503 0.248 0.23  0.018]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.618 0.088 0.291]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.007 0.628 0.074 0.291]\n",
      "\n",
      "Epoch 13/100, Total Loss: 6.526\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.162 0.256 0.097 0.485]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.492 0.257 0.232 0.019]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.6   0.093 0.303]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.008 0.591 0.075 0.326]\n",
      "\n",
      "Epoch 14/100, Total Loss: 6.318\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.165 0.264 0.097 0.474]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.481 0.266 0.233 0.019]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.583 0.099 0.315]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.009 0.554 0.075 0.362]\n",
      "\n",
      "Epoch 15/100, Total Loss: 6.120\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.167 0.272 0.098 0.463]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.471 0.275 0.234 0.02 ]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.568 0.105 0.325]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.011 0.517 0.075 0.397]\n",
      "\n",
      "Epoch 16/100, Total Loss: 5.932\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.17  0.28  0.098 0.451]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.461 0.283 0.235 0.02 ]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.553 0.111 0.333]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.012 0.483 0.074 0.431]\n",
      "\n",
      "Epoch 17/100, Total Loss: 5.756\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.172 0.289 0.099 0.44 ]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.451 0.291 0.237 0.021]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.539 0.118 0.34 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.013 0.451 0.073 0.462]\n",
      "\n",
      "Epoch 18/100, Total Loss: 5.591\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.175 0.297 0.1   0.428]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.442 0.298 0.238 0.021]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.525 0.125 0.346]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.015 0.423 0.071 0.491]\n",
      "\n",
      "Epoch 19/100, Total Loss: 5.438\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.178 0.306 0.1   0.417]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.433 0.305 0.239 0.022]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.513 0.133 0.351]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.016 0.397 0.069 0.517]\n",
      "\n",
      "Epoch 20/100, Total Loss: 5.295\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.18  0.314 0.101 0.405]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.425 0.312 0.24  0.022]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.501 0.141 0.355]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.018 0.375 0.067 0.54 ]\n",
      "\n",
      "Epoch 21/100, Total Loss: 5.161\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.182 0.323 0.102 0.393]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.417 0.319 0.242 0.023]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.489 0.149 0.359]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.019 0.355 0.066 0.56 ]\n",
      "\n",
      "Epoch 22/100, Total Loss: 5.033\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.184 0.331 0.103 0.382]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.409 0.325 0.243 0.024]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.477 0.158 0.361]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.021 0.338 0.064 0.578]\n",
      "\n",
      "Epoch 23/100, Total Loss: 4.913\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.186 0.34  0.104 0.371]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.401 0.331 0.244 0.024]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.003 0.465 0.168 0.364]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.022 0.323 0.062 0.593]\n",
      "\n",
      "Epoch 24/100, Total Loss: 4.798\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 0, 1]' with probabilities [0.188 0.349 0.104 0.359]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.393 0.337 0.245 0.025]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.454 0.178 0.365]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.023 0.31  0.061 0.606]\n",
      "\n",
      "Epoch 25/100, Total Loss: 4.689\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.189 0.357 0.105 0.349]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.386 0.342 0.247 0.025]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.442 0.188 0.367]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.025 0.3   0.059 0.616]\n",
      "\n",
      "Epoch 26/100, Total Loss: 4.585\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.19  0.366 0.106 0.338]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.379 0.347 0.248 0.026]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.43  0.199 0.368]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.026 0.291 0.058 0.625]\n",
      "\n",
      "Epoch 27/100, Total Loss: 4.485\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.191 0.374 0.107 0.328]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.372 0.352 0.25  0.027]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.418 0.21  0.368]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.027 0.284 0.057 0.632]\n",
      "\n",
      "Epoch 28/100, Total Loss: 4.389\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.192 0.382 0.108 0.318]\n",
      "  Step 2: '[1, 0, 0, 0]' with probabilities [0.365 0.356 0.251 0.027]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.405 0.222 0.368]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.028 0.278 0.056 0.637]\n",
      "\n",
      "Epoch 29/100, Total Loss: 4.296\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.193 0.39  0.109 0.308]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.359 0.36  0.253 0.028]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.393 0.235 0.368]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.029 0.274 0.055 0.642]\n",
      "\n",
      "Epoch 30/100, Total Loss: 4.206\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.193 0.398 0.11  0.299]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.353 0.364 0.255 0.028]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.381 0.248 0.367]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.03  0.27  0.054 0.645]\n",
      "\n",
      "Epoch 31/100, Total Loss: 4.119\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.194 0.405 0.111 0.29 ]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.346 0.367 0.257 0.029]\n",
      "  Step 3: '[0, 1, 0, 0]' with probabilities [0.004 0.368 0.262 0.366]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.031 0.268 0.054 0.648]\n",
      "\n",
      "Epoch 32/100, Total Loss: 4.034\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.194 0.413 0.112 0.281]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.341 0.37  0.26  0.03 ]\n",
      "  Step 3: '[0, 0, 0, 1]' with probabilities [0.004 0.355 0.276 0.364]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.032 0.266 0.053 0.649]\n",
      "\n",
      "Epoch 33/100, Total Loss: 3.951\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.194 0.42  0.113 0.273]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.335 0.373 0.262 0.03 ]\n",
      "  Step 3: '[0, 0, 0, 1]' with probabilities [0.004 0.342 0.292 0.362]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.033 0.265 0.053 0.65 ]\n",
      "\n",
      "Epoch 34/100, Total Loss: 3.870\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.194 0.426 0.115 0.265]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.329 0.375 0.265 0.031]\n",
      "  Step 3: '[0, 0, 0, 1]' with probabilities [0.004 0.329 0.307 0.359]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.033 0.264 0.053 0.65 ]\n",
      "\n",
      "Epoch 35/100, Total Loss: 3.790\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.193 0.433 0.116 0.258]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.324 0.376 0.268 0.031]\n",
      "  Step 3: '[0, 0, 0, 1]' with probabilities [0.004 0.316 0.324 0.356]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.034 0.264 0.052 0.649]\n",
      "\n",
      "Epoch 36/100, Total Loss: 3.712\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.193 0.439 0.117 0.251]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.319 0.378 0.272 0.032]\n",
      "  Step 3: '[0, 0, 0, 1]' with probabilities [0.005 0.302 0.341 0.352]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.034 0.265 0.052 0.648]\n",
      "\n",
      "Epoch 37/100, Total Loss: 3.635\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.193 0.445 0.118 0.245]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.314 0.379 0.275 0.032]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.005 0.289 0.359 0.347]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.266 0.053 0.646]\n",
      "\n",
      "Epoch 38/100, Total Loss: 3.560\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.192 0.45  0.119 0.239]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.309 0.379 0.279 0.033]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.005 0.275 0.378 0.342]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.268 0.053 0.644]\n",
      "\n",
      "Epoch 39/100, Total Loss: 3.486\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.191 0.456 0.12  0.233]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.304 0.379 0.284 0.033]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.005 0.261 0.398 0.336]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.27  0.053 0.641]\n",
      "\n",
      "Epoch 40/100, Total Loss: 3.413\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.191 0.46  0.121 0.228]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.3   0.379 0.288 0.033]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.005 0.248 0.418 0.329]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.273 0.054 0.637]\n",
      "\n",
      "Epoch 41/100, Total Loss: 3.342\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.19  0.465 0.122 0.223]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.295 0.378 0.293 0.034]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.005 0.234 0.44  0.321]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.277 0.054 0.633]\n",
      "\n",
      "Epoch 42/100, Total Loss: 3.272\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.189 0.469 0.123 0.219]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.291 0.377 0.298 0.034]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.005 0.22  0.462 0.312]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.281 0.055 0.627]\n",
      "\n",
      "Epoch 43/100, Total Loss: 3.205\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.188 0.473 0.124 0.215]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.286 0.376 0.304 0.034]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.006 0.207 0.485 0.302]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.287 0.056 0.621]\n",
      "\n",
      "Epoch 44/100, Total Loss: 3.140\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.187 0.476 0.126 0.211]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.282 0.374 0.31  0.034]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.006 0.193 0.509 0.292]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.293 0.058 0.613]\n",
      "\n",
      "Epoch 45/100, Total Loss: 3.077\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.186 0.479 0.127 0.208]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.278 0.372 0.316 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.006 0.18  0.534 0.281]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.299 0.06  0.605]\n",
      "\n",
      "Epoch 46/100, Total Loss: 3.018\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.185 0.482 0.128 0.206]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.274 0.369 0.322 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.006 0.166 0.559 0.269]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.307 0.062 0.595]\n",
      "\n",
      "Epoch 47/100, Total Loss: 2.963\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.183 0.484 0.129 0.204]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.27  0.366 0.329 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.006 0.153 0.584 0.256]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.317 0.065 0.583]\n",
      "\n",
      "Epoch 48/100, Total Loss: 2.913\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.182 0.486 0.129 0.202]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.266 0.363 0.336 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.007 0.141 0.609 0.243]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.327 0.068 0.57 ]\n",
      "\n",
      "Epoch 49/100, Total Loss: 2.868\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.181 0.488 0.13  0.201]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.262 0.359 0.344 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.007 0.129 0.634 0.23 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.339 0.071 0.555]\n",
      "\n",
      "Epoch 50/100, Total Loss: 2.830\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.179 0.489 0.131 0.201]\n",
      "  Step 2: '[0, 1, 0, 0]' with probabilities [0.258 0.356 0.351 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.007 0.118 0.658 0.217]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.034 0.351 0.076 0.539]\n",
      "\n",
      "Epoch 51/100, Total Loss: 2.799\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.178 0.49  0.132 0.201]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.254 0.351 0.359 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.007 0.107 0.681 0.204]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.034 0.365 0.08  0.52 ]\n",
      "\n",
      "Epoch 52/100, Total Loss: 2.775\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.176 0.49  0.132 0.201]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.25  0.347 0.368 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.007 0.098 0.702 0.192]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.034 0.379 0.086 0.501]\n",
      "\n",
      "Epoch 53/100, Total Loss: 2.758\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.174 0.49  0.133 0.202]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.246 0.343 0.376 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.008 0.089 0.723 0.18 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.034 0.394 0.091 0.481]\n",
      "\n",
      "Epoch 54/100, Total Loss: 2.747\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.173 0.491 0.133 0.203]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.241 0.339 0.384 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.008 0.082 0.741 0.169]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.033 0.408 0.097 0.461]\n",
      "\n",
      "Epoch 55/100, Total Loss: 2.741\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.171 0.49  0.134 0.204]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.237 0.334 0.393 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.008 0.075 0.758 0.158]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.033 0.421 0.104 0.442]\n",
      "\n",
      "Epoch 56/100, Total Loss: 2.741\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.17  0.49  0.134 0.206]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.233 0.33  0.402 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.008 0.069 0.774 0.149]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.033 0.433 0.111 0.423]\n",
      "\n",
      "Epoch 57/100, Total Loss: 2.742\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.168 0.49  0.134 0.208]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.229 0.325 0.41  0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.008 0.064 0.787 0.14 ]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.443 0.118 0.406]\n",
      "\n",
      "Epoch 58/100, Total Loss: 2.745\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.166 0.489 0.134 0.21 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.224 0.32  0.419 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.009 0.06  0.799 0.132]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.449 0.125 0.394]\n",
      "\n",
      "Epoch 59/100, Total Loss: 2.740\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.164 0.489 0.134 0.212]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.22  0.316 0.428 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.009 0.057 0.809 0.125]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.451 0.131 0.386]\n",
      "\n",
      "Epoch 60/100, Total Loss: 2.726\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.162 0.49  0.134 0.214]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.215 0.311 0.437 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.009 0.053 0.818 0.119]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.449 0.137 0.383]\n",
      "\n",
      "Epoch 61/100, Total Loss: 2.703\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.16  0.49  0.133 0.217]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.211 0.306 0.446 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.009 0.051 0.827 0.113]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.443 0.143 0.383]\n",
      "\n",
      "Epoch 62/100, Total Loss: 2.671\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.157 0.491 0.133 0.219]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.206 0.302 0.455 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.01  0.048 0.834 0.108]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.434 0.148 0.386]\n",
      "\n",
      "Epoch 63/100, Total Loss: 2.632\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.155 0.492 0.132 0.222]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.201 0.298 0.464 0.037]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.01  0.046 0.84  0.104]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.423 0.153 0.392]\n",
      "\n",
      "Epoch 64/100, Total Loss: 2.586\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.152 0.494 0.131 0.224]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.197 0.293 0.473 0.037]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.01  0.044 0.846 0.1  ]\n",
      "  Step 4: '[0, 1, 0, 0]' with probabilities [0.032 0.408 0.158 0.401]\n",
      "\n",
      "Epoch 65/100, Total Loss: 2.535\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.149 0.495 0.129 0.226]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.192 0.289 0.482 0.037]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.01  0.043 0.851 0.096]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.033 0.392 0.163 0.412]\n",
      "\n",
      "Epoch 66/100, Total Loss: 2.481\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.146 0.498 0.128 0.229]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.187 0.285 0.49  0.038]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.011 0.041 0.856 0.092]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.033 0.374 0.168 0.425]\n",
      "\n",
      "Epoch 67/100, Total Loss: 2.423\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.143 0.5   0.126 0.231]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.183 0.281 0.498 0.038]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.011 0.04  0.86  0.089]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.034 0.354 0.173 0.439]\n",
      "\n",
      "Epoch 68/100, Total Loss: 2.365\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.139 0.503 0.125 0.233]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.178 0.277 0.506 0.039]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.011 0.039 0.863 0.086]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.333 0.178 0.454]\n",
      "\n",
      "Epoch 69/100, Total Loss: 2.305\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.136 0.506 0.123 0.235]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.174 0.273 0.514 0.039]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.012 0.038 0.866 0.084]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.311 0.184 0.469]\n",
      "\n",
      "Epoch 70/100, Total Loss: 2.246\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.132 0.51  0.121 0.236]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.169 0.27  0.521 0.04 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.012 0.037 0.869 0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.289 0.191 0.485]\n",
      "\n",
      "Epoch 71/100, Total Loss: 2.189\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.129 0.515 0.119 0.237]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.164 0.267 0.528 0.041]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.013 0.036 0.871 0.08 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.037 0.266 0.198 0.5  ]\n",
      "\n",
      "Epoch 72/100, Total Loss: 2.134\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.125 0.52  0.117 0.237]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.16  0.264 0.534 0.042]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.013 0.036 0.873 0.078]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.038 0.243 0.206 0.514]\n",
      "\n",
      "Epoch 73/100, Total Loss: 2.083\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.122 0.526 0.115 0.237]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.155 0.262 0.54  0.043]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.014 0.035 0.874 0.077]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.039 0.22  0.214 0.526]\n",
      "\n",
      "Epoch 74/100, Total Loss: 2.037\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.119 0.531 0.113 0.237]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.151 0.26  0.545 0.044]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.015 0.035 0.874 0.076]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.04  0.199 0.224 0.537]\n",
      "\n",
      "Epoch 75/100, Total Loss: 1.997\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.115 0.538 0.11  0.237]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.147 0.259 0.549 0.045]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.016 0.035 0.874 0.075]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.041 0.179 0.234 0.545]\n",
      "\n",
      "Epoch 76/100, Total Loss: 1.961\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.112 0.544 0.108 0.236]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.143 0.257 0.554 0.046]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.016 0.035 0.874 0.075]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.043 0.161 0.245 0.552]\n",
      "\n",
      "Epoch 77/100, Total Loss: 1.929\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.109 0.551 0.106 0.235]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.139 0.256 0.558 0.047]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.017 0.035 0.873 0.075]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.044 0.143 0.255 0.557]\n",
      "\n",
      "Epoch 78/100, Total Loss: 1.901\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.106 0.557 0.104 0.233]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.136 0.255 0.562 0.047]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.018 0.035 0.872 0.075]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.046 0.128 0.265 0.561]\n",
      "\n",
      "Epoch 79/100, Total Loss: 1.876\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.103 0.564 0.101 0.232]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.133 0.253 0.566 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.019 0.035 0.871 0.076]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.047 0.115 0.274 0.564]\n",
      "\n",
      "Epoch 80/100, Total Loss: 1.853\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.101 0.57  0.099 0.23 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.13  0.251 0.571 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.02  0.035 0.869 0.076]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.048 0.103 0.282 0.566]\n",
      "\n",
      "Epoch 81/100, Total Loss: 1.832\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.098 0.576 0.097 0.228]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.127 0.25  0.575 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.021 0.035 0.866 0.077]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.049 0.094 0.289 0.568]\n",
      "\n",
      "Epoch 82/100, Total Loss: 1.812\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.096 0.582 0.096 0.226]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.124 0.247 0.58  0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.022 0.035 0.864 0.079]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.05  0.086 0.294 0.57 ]\n",
      "\n",
      "Epoch 83/100, Total Loss: 1.796\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.094 0.588 0.094 0.224]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.122 0.245 0.585 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.023 0.035 0.86  0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.052 0.079 0.299 0.57 ]\n",
      "\n",
      "Epoch 84/100, Total Loss: 1.781\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.092 0.593 0.092 0.223]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.12  0.242 0.59  0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.024 0.036 0.856 0.084]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.054 0.073 0.304 0.569]\n",
      "\n",
      "Epoch 85/100, Total Loss: 1.770\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.09  0.597 0.091 0.221]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.118 0.239 0.595 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.025 0.036 0.852 0.088]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.057 0.069 0.308 0.566]\n",
      "\n",
      "Epoch 86/100, Total Loss: 1.763\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.089 0.602 0.089 0.22 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.116 0.237 0.6   0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.025 0.036 0.846 0.093]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.061 0.066 0.311 0.562]\n",
      "\n",
      "Epoch 87/100, Total Loss: 1.761\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.087 0.606 0.088 0.219]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.114 0.233 0.606 0.047]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.025 0.036 0.84  0.099]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.066 0.063 0.315 0.557]\n",
      "\n",
      "Epoch 88/100, Total Loss: 1.763\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.086 0.609 0.087 0.218]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.112 0.23  0.611 0.046]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.026 0.036 0.832 0.106]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.072 0.061 0.317 0.55 ]\n",
      "\n",
      "Epoch 89/100, Total Loss: 1.770\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.084 0.612 0.085 0.218]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.111 0.227 0.617 0.045]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.026 0.036 0.824 0.115]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.08  0.06  0.318 0.542]\n",
      "\n",
      "Epoch 90/100, Total Loss: 1.781\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.083 0.615 0.084 0.218]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.109 0.224 0.623 0.044]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.025 0.036 0.813 0.126]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.091 0.058 0.316 0.534]\n",
      "\n",
      "Epoch 91/100, Total Loss: 1.794\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.082 0.617 0.083 0.218]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.108 0.221 0.628 0.043]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.025 0.035 0.801 0.139]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.105 0.057 0.311 0.527]\n",
      "\n",
      "Epoch 92/100, Total Loss: 1.809\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.081 0.619 0.081 0.219]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.107 0.217 0.634 0.042]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.024 0.035 0.788 0.153]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.121 0.056 0.302 0.521]\n",
      "\n",
      "Epoch 93/100, Total Loss: 1.825\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.08 0.62 0.08 0.22]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.105 0.214 0.64  0.041]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.023 0.034 0.773 0.169]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.14  0.054 0.288 0.518]\n",
      "\n",
      "Epoch 94/100, Total Loss: 1.839\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.079 0.621 0.078 0.221]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.104 0.211 0.646 0.039]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.022 0.033 0.758 0.187]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.16  0.052 0.27  0.517]\n",
      "\n",
      "Epoch 95/100, Total Loss: 1.848\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.078 0.622 0.077 0.223]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.102 0.207 0.653 0.038]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.021 0.032 0.743 0.204]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.181 0.049 0.249 0.52 ]\n",
      "\n",
      "Epoch 96/100, Total Loss: 1.852\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.077 0.623 0.076 0.224]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.1   0.204 0.659 0.036]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.02  0.031 0.728 0.221]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.202 0.046 0.227 0.525]\n",
      "\n",
      "Epoch 97/100, Total Loss: 1.851\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.076 0.624 0.074 0.226]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.099 0.2   0.666 0.035]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.019 0.03  0.713 0.238]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.221 0.043 0.204 0.533]\n",
      "\n",
      "Epoch 98/100, Total Loss: 1.846\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.075 0.625 0.073 0.227]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.097 0.197 0.673 0.034]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.018 0.029 0.7   0.253]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.237 0.04  0.182 0.542]\n",
      "\n",
      "Epoch 99/100, Total Loss: 1.837\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.074 0.626 0.072 0.228]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.095 0.193 0.68  0.032]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.017 0.028 0.688 0.267]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.25  0.036 0.162 0.552]\n",
      "\n",
      "Epoch 100/100, Total Loss: 1.823\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.073 0.627 0.07  0.229]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.092 0.19  0.687 0.031]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.017 0.027 0.677 0.28 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.259 0.033 0.144 0.564]\n"
     ]
    }
   ],
   "source": [
    "# vanilla\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# One-hot encoded input and target sequences for the word \"hello\"\n",
    "input_sequence = [\n",
    "    [1, 0, 0, 0],  # h\n",
    "    [0, 1, 0, 0],  # e\n",
    "    [0, 0, 1, 0],  # l\n",
    "    [0, 0, 1, 0]   # l\n",
    "]\n",
    "\n",
    "target_sequence = [\n",
    "    [0, 1, 0, 0],  # e (target for h)\n",
    "    [0, 0, 1, 0],  # l (target for e)\n",
    "    [0, 0, 1, 0],  # l (target for l)\n",
    "    [0, 0, 0, 1]   # o (target for l)\n",
    "]\n",
    "\n",
    "# Create a dictionary to map one-hot vectors to letters\n",
    "idx_to_char = {\n",
    "    str([1, 0, 0, 0]): 'h',\n",
    "    str([0, 1, 0, 0]): 'e',\n",
    "    str([0, 0, 1, 0]): 'l',\n",
    "    str([0, 0, 0, 1]): 'o'\n",
    "}\n",
    "\n",
    "# Initialize RNN parameters\n",
    "h_size = 7\n",
    "W_hx = np.random.randn(4, h_size)  # input to hidden\n",
    "W_yh = np.random.randn(h_size, 4)  # hidden to output\n",
    "W_hh = np.random.randn(h_size, h_size)  # hidden to hidden\n",
    "b_h = np.zeros(h_size)  # hidden layer bias\n",
    "b_y = np.zeros(4)       # output layer bias\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Define helper functions\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # numerical stability\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    h = np.zeros(h_size)  # initialize hidden state for each epoch\n",
    "    \n",
    "    # Gradients initialization for accumulating over timesteps\n",
    "    dW_hx = np.zeros_like(W_hx)\n",
    "    dW_hh = np.zeros_like(W_hh)\n",
    "    dW_yh = np.zeros_like(W_yh)\n",
    "    db_h = np.zeros_like(b_h)\n",
    "    db_y = np.zeros_like(b_y)\n",
    "    dh_next = np.zeros_like(h)\n",
    "    \n",
    "    # Forward and backward pass for each timestep\n",
    "    for i in range(len(input_sequence)):\n",
    "        x = np.array(input_sequence[i])\n",
    "        y = np.array(target_sequence[i])\n",
    "        \n",
    "        # Forward pass\n",
    "        a = np.dot(x, W_hx) + np.dot(h, W_hh) + b_h\n",
    "        h = np.tanh(a)\n",
    "        z = np.dot(h, W_yh) + b_y\n",
    "        y_hat = softmax(z)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = -np.sum(y * np.log(y_hat + 1e-7))\n",
    "        total_loss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "        dy = y_hat - y  # derivative of cross-entropy loss w.r.t output\n",
    "        dW_yh += np.outer(h, dy)\n",
    "        db_y += dy\n",
    "\n",
    "        dh = np.dot(W_yh, dy) + dh_next  # gradient for hidden state\n",
    "        db = (1 - h ** 2) * dh           # backprop through tanh activation\n",
    "\n",
    "        dW_hx += np.outer(x, db)\n",
    "        dW_hh += np.outer(h, db)\n",
    "        db_h += db\n",
    "        \n",
    "        # Pass the gradient to the next timestep\n",
    "        dh_next = np.dot(W_hh, db)\n",
    "        \n",
    "    \n",
    "    # Clip gradients to prevent exploding gradients\n",
    "    for dparam in [dW_hx, dW_hh, dW_yh, db_h, db_y]:\n",
    "        np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "    # Update parameters\n",
    "    W_hx -= learning_rate * dW_hx\n",
    "    W_hh -= learning_rate * dW_hh\n",
    "    W_yh -= learning_rate * dW_yh\n",
    "    b_h -= learning_rate * db_h\n",
    "    b_y -= learning_rate * db_y\n",
    "\n",
    "    # Print total loss and outcome for this epoch\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}, Total Loss: {total_loss:.3f}\")\n",
    "    print(\"Predicted sequence:\")\n",
    "\n",
    "    # Forward pass through the sequence to print predictions\n",
    "    h = np.zeros(h_size)  # reset hidden state for prediction\n",
    "    for i in range(len(input_sequence)):\n",
    "        x = np.array(input_sequence[i])\n",
    "        b = np.dot(x, W_hx) + np.dot(h, W_hh) + b_h\n",
    "        h = np.tanh(b)\n",
    "        a = np.dot(h, W_yh) + b_y\n",
    "        output = softmax(a)\n",
    "        \n",
    "        # Find the character with the highest probability\n",
    "        predicted_char = max(idx_to_char, key=lambda k: output[int(k.strip('[]').split(', ').index('1'))])\n",
    "        print(f\"  Step {i+1}: '{predicted_char}' with probabilities {output.round(3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100, Total Loss: 6.553\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.055 0.204 0.684 0.057]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.03  0.394 0.506 0.069]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.292 0.185 0.436 0.087]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.868 0.024 0.068 0.041]\n",
      "\n",
      "Epoch 2/100, Total Loss: 6.305\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.052 0.212 0.678 0.058]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.033 0.388 0.511 0.068]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.274 0.189 0.446 0.091]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.846 0.028 0.078 0.048]\n",
      "\n",
      "Epoch 3/100, Total Loss: 6.056\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.049 0.221 0.671 0.059]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.035 0.381 0.517 0.067]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.257 0.194 0.454 0.095]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.819 0.032 0.09  0.058]\n",
      "\n",
      "Epoch 4/100, Total Loss: 5.808\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.046 0.23  0.663 0.06 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.038 0.373 0.523 0.066]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.242 0.198 0.462 0.099]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.788 0.038 0.105 0.069]\n",
      "\n",
      "Epoch 5/100, Total Loss: 5.562\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.044 0.24  0.655 0.061]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.041 0.365 0.529 0.065]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.227 0.202 0.468 0.103]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.752 0.045 0.121 0.082]\n",
      "\n",
      "Epoch 6/100, Total Loss: 5.321\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.042 0.249 0.647 0.062]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.044 0.356 0.536 0.064]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.214 0.206 0.473 0.106]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.711 0.052 0.139 0.098]\n",
      "\n",
      "Epoch 7/100, Total Loss: 5.087\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.04  0.259 0.639 0.062]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.047 0.347 0.542 0.063]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.202 0.21  0.478 0.11 ]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.665 0.061 0.159 0.115]\n",
      "\n",
      "Epoch 8/100, Total Loss: 4.862\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.038 0.269 0.63  0.063]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.05  0.338 0.55  0.062]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.19  0.214 0.482 0.114]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.615 0.07  0.181 0.134]\n",
      "\n",
      "Epoch 9/100, Total Loss: 4.647\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.036 0.279 0.621 0.064]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.053 0.328 0.557 0.061]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.179 0.218 0.486 0.118]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.562 0.08  0.203 0.155]\n",
      "\n",
      "Epoch 10/100, Total Loss: 4.444\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.034 0.29  0.612 0.064]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.056 0.318 0.565 0.06 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.169 0.221 0.489 0.121]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.509 0.09  0.224 0.177]\n",
      "\n",
      "Epoch 11/100, Total Loss: 4.257\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.033 0.3   0.602 0.065]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.059 0.308 0.574 0.06 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.16  0.224 0.493 0.123]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.458 0.099 0.244 0.199]\n",
      "\n",
      "Epoch 12/100, Total Loss: 4.085\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.031 0.31  0.593 0.066]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.062 0.297 0.582 0.059]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.152 0.226 0.496 0.126]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.411 0.107 0.262 0.22 ]\n",
      "\n",
      "Epoch 13/100, Total Loss: 3.929\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.03  0.32  0.584 0.066]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.065 0.287 0.591 0.058]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.145 0.228 0.5   0.127]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.367 0.115 0.278 0.24 ]\n",
      "\n",
      "Epoch 14/100, Total Loss: 3.785\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.029 0.33  0.575 0.066]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.067 0.276 0.6   0.057]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.138 0.229 0.505 0.129]\n",
      "  Step 4: '[1, 0, 0, 0]' with probabilities [0.328 0.122 0.291 0.26 ]\n",
      "\n",
      "Epoch 15/100, Total Loss: 3.652\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.028 0.34  0.565 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.069 0.266 0.608 0.056]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.132 0.229 0.509 0.13 ]\n",
      "  Step 4: '[0, 0, 1, 0]' with probabilities [0.293 0.127 0.301 0.278]\n",
      "\n",
      "Epoch 16/100, Total Loss: 3.530\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.027 0.35  0.556 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.072 0.256 0.617 0.055]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.127 0.229 0.514 0.13 ]\n",
      "  Step 4: '[0, 0, 1, 0]' with probabilities [0.262 0.132 0.31  0.296]\n",
      "\n",
      "Epoch 17/100, Total Loss: 3.416\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.025 0.36  0.547 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.074 0.246 0.626 0.055]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.121 0.229 0.519 0.13 ]\n",
      "  Step 4: '[0, 0, 1, 0]' with probabilities [0.235 0.136 0.316 0.313]\n",
      "\n",
      "Epoch 18/100, Total Loss: 3.308\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.024 0.37  0.538 0.068]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.076 0.236 0.634 0.054]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.117 0.229 0.524 0.13 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.211 0.139 0.321 0.329]\n",
      "\n",
      "Epoch 19/100, Total Loss: 3.207\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.024 0.38  0.529 0.068]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.078 0.226 0.642 0.054]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.112 0.228 0.529 0.13 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.19  0.141 0.324 0.345]\n",
      "\n",
      "Epoch 20/100, Total Loss: 3.110\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.023 0.39  0.52  0.068]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.079 0.217 0.65  0.053]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.108 0.228 0.534 0.13 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.171 0.143 0.325 0.36 ]\n",
      "\n",
      "Epoch 21/100, Total Loss: 3.019\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.022 0.4   0.511 0.068]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.081 0.208 0.658 0.053]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.105 0.227 0.54  0.129]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.155 0.144 0.326 0.375]\n",
      "\n",
      "Epoch 22/100, Total Loss: 2.932\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.021 0.41  0.502 0.068]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.083 0.199 0.666 0.052]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.101 0.226 0.545 0.128]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.141 0.145 0.325 0.389]\n",
      "\n",
      "Epoch 23/100, Total Loss: 2.850\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.02  0.419 0.493 0.068]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.084 0.191 0.673 0.052]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.098 0.225 0.55  0.127]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.129 0.145 0.323 0.403]\n",
      "\n",
      "Epoch 24/100, Total Loss: 2.771\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.019 0.429 0.484 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.085 0.183 0.68  0.052]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.095 0.223 0.556 0.126]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.119 0.145 0.321 0.415]\n",
      "\n",
      "Epoch 25/100, Total Loss: 2.698\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.019 0.438 0.476 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.086 0.176 0.686 0.052]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.093 0.222 0.562 0.124]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.111 0.144 0.319 0.426]\n",
      "\n",
      "Epoch 26/100, Total Loss: 2.630\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.018 0.448 0.467 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.087 0.169 0.692 0.052]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.09  0.22  0.567 0.123]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.104 0.142 0.317 0.436]\n",
      "\n",
      "Epoch 27/100, Total Loss: 2.568\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.017 0.457 0.459 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.087 0.163 0.698 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.088 0.218 0.573 0.121]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.099 0.14  0.316 0.445]\n",
      "\n",
      "Epoch 28/100, Total Loss: 2.509\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.017 0.466 0.451 0.067]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.088 0.157 0.704 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.086 0.215 0.579 0.12 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.094 0.138 0.315 0.452]\n",
      "\n",
      "Epoch 29/100, Total Loss: 2.455\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.016 0.475 0.443 0.066]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.088 0.152 0.709 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.084 0.213 0.585 0.118]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.09  0.136 0.315 0.459]\n",
      "\n",
      "Epoch 30/100, Total Loss: 2.403\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.016 0.483 0.435 0.066]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.088 0.147 0.715 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.082 0.211 0.59  0.117]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.086 0.134 0.314 0.466]\n",
      "\n",
      "Epoch 31/100, Total Loss: 2.354\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.015 0.492 0.427 0.066]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.088 0.142 0.72  0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.08  0.208 0.596 0.115]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.083 0.132 0.314 0.471]\n",
      "\n",
      "Epoch 32/100, Total Loss: 2.308\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.015 0.5   0.419 0.066]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.087 0.138 0.725 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.079 0.206 0.602 0.114]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.08  0.129 0.314 0.477]\n",
      "\n",
      "Epoch 33/100, Total Loss: 2.264\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.015 0.508 0.412 0.065]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.087 0.133 0.73  0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.077 0.203 0.607 0.112]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.078 0.127 0.314 0.482]\n",
      "\n",
      "Epoch 34/100, Total Loss: 2.222\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.014 0.516 0.405 0.065]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.087 0.129 0.734 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.076 0.201 0.612 0.111]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.076 0.125 0.313 0.486]\n",
      "\n",
      "Epoch 35/100, Total Loss: 2.182\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.014 0.524 0.397 0.065]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.086 0.125 0.739 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.074 0.199 0.618 0.109]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.074 0.122 0.313 0.491]\n",
      "\n",
      "Epoch 36/100, Total Loss: 2.143\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.014 0.532 0.39  0.064]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.086 0.122 0.743 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.073 0.196 0.623 0.108]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.072 0.12  0.313 0.495]\n",
      "\n",
      "Epoch 37/100, Total Loss: 2.106\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.013 0.539 0.384 0.064]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.085 0.118 0.747 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.072 0.194 0.628 0.107]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.07  0.118 0.313 0.499]\n",
      "\n",
      "Epoch 38/100, Total Loss: 2.071\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.013 0.547 0.377 0.064]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.085 0.115 0.751 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.071 0.191 0.632 0.106]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.069 0.116 0.314 0.502]\n",
      "\n",
      "Epoch 39/100, Total Loss: 2.037\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.013 0.554 0.37  0.063]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.084 0.112 0.755 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.069 0.189 0.637 0.104]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.067 0.113 0.314 0.506]\n",
      "\n",
      "Epoch 40/100, Total Loss: 2.005\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.012 0.561 0.364 0.063]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.083 0.109 0.759 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.068 0.186 0.642 0.103]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.066 0.111 0.314 0.509]\n",
      "\n",
      "Epoch 41/100, Total Loss: 1.973\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.012 0.568 0.358 0.063]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.083 0.106 0.762 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.067 0.184 0.647 0.102]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.065 0.109 0.314 0.512]\n",
      "\n",
      "Epoch 42/100, Total Loss: 1.943\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.012 0.574 0.352 0.062]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.082 0.104 0.766 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.066 0.181 0.651 0.101]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.064 0.107 0.314 0.515]\n",
      "\n",
      "Epoch 43/100, Total Loss: 1.914\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.012 0.581 0.346 0.062]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.081 0.101 0.769 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.065 0.179 0.655 0.1  ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.063 0.105 0.314 0.518]\n",
      "\n",
      "Epoch 44/100, Total Loss: 1.886\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.011 0.587 0.34  0.061]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.081 0.099 0.773 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.064 0.177 0.66  0.099]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.062 0.104 0.314 0.521]\n",
      "\n",
      "Epoch 45/100, Total Loss: 1.859\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.011 0.594 0.334 0.061]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.08  0.096 0.776 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.063 0.174 0.664 0.098]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.061 0.102 0.314 0.523]\n",
      "\n",
      "Epoch 46/100, Total Loss: 1.832\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.011 0.6   0.329 0.061]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.079 0.094 0.779 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.062 0.172 0.668 0.098]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.06  0.1   0.314 0.526]\n",
      "\n",
      "Epoch 47/100, Total Loss: 1.807\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.011 0.606 0.323 0.06 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.078 0.092 0.782 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.062 0.17  0.672 0.097]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.059 0.098 0.314 0.528]\n",
      "\n",
      "Epoch 48/100, Total Loss: 1.782\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.011 0.612 0.318 0.06 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.077 0.09  0.785 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.061 0.167 0.676 0.096]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.058 0.097 0.314 0.531]\n",
      "\n",
      "Epoch 49/100, Total Loss: 1.759\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.01  0.617 0.313 0.06 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.077 0.088 0.788 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.06  0.165 0.68  0.095]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.058 0.095 0.314 0.533]\n",
      "\n",
      "Epoch 50/100, Total Loss: 1.735\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.01  0.623 0.308 0.059]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.076 0.086 0.791 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.059 0.163 0.684 0.094]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.057 0.094 0.314 0.536]\n",
      "\n",
      "Epoch 51/100, Total Loss: 1.713\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.01  0.628 0.303 0.059]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.075 0.084 0.793 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.058 0.161 0.687 0.094]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.056 0.092 0.314 0.538]\n",
      "\n",
      "Epoch 52/100, Total Loss: 1.691\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.01  0.634 0.298 0.058]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.074 0.082 0.796 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.058 0.158 0.691 0.093]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.055 0.091 0.314 0.54 ]\n",
      "\n",
      "Epoch 53/100, Total Loss: 1.670\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.01  0.639 0.293 0.058]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.074 0.08  0.798 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.057 0.156 0.694 0.092]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.055 0.089 0.313 0.543]\n",
      "\n",
      "Epoch 54/100, Total Loss: 1.649\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.01  0.644 0.289 0.058]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.073 0.079 0.801 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.056 0.154 0.698 0.092]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.054 0.088 0.313 0.545]\n",
      "\n",
      "Epoch 55/100, Total Loss: 1.629\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.649 0.284 0.057]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.072 0.077 0.803 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.055 0.152 0.701 0.091]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.054 0.086 0.313 0.547]\n",
      "\n",
      "Epoch 56/100, Total Loss: 1.609\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.654 0.28  0.057]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.071 0.076 0.806 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.055 0.15  0.705 0.091]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.053 0.085 0.313 0.549]\n",
      "\n",
      "Epoch 57/100, Total Loss: 1.590\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.659 0.276 0.056]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.071 0.074 0.808 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.054 0.148 0.708 0.09 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.052 0.084 0.312 0.551]\n",
      "\n",
      "Epoch 58/100, Total Loss: 1.572\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.663 0.272 0.056]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.07  0.073 0.81  0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.053 0.146 0.711 0.09 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.052 0.083 0.312 0.554]\n",
      "\n",
      "Epoch 59/100, Total Loss: 1.554\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.668 0.268 0.056]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.069 0.071 0.812 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.053 0.144 0.714 0.089]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.051 0.081 0.312 0.556]\n",
      "\n",
      "Epoch 60/100, Total Loss: 1.536\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.672 0.264 0.055]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.068 0.07  0.814 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.052 0.142 0.717 0.089]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.051 0.08  0.311 0.558]\n",
      "\n",
      "Epoch 61/100, Total Loss: 1.519\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.677 0.26  0.055]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.068 0.069 0.816 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.052 0.14  0.72  0.088]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.05  0.079 0.311 0.56 ]\n",
      "\n",
      "Epoch 62/100, Total Loss: 1.502\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.681 0.256 0.055]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.067 0.067 0.818 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.051 0.138 0.723 0.088]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.05  0.078 0.31  0.562]\n",
      "\n",
      "Epoch 63/100, Total Loss: 1.485\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.685 0.253 0.054]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.066 0.066 0.82  0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.051 0.136 0.726 0.088]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.049 0.077 0.31  0.564]\n",
      "\n",
      "Epoch 64/100, Total Loss: 1.469\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.689 0.249 0.054]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.066 0.065 0.822 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.05  0.134 0.729 0.087]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.049 0.076 0.309 0.566]\n",
      "\n",
      "Epoch 65/100, Total Loss: 1.454\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.693 0.245 0.054]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.065 0.064 0.824 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.049 0.132 0.732 0.087]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.048 0.075 0.309 0.568]\n",
      "\n",
      "Epoch 66/100, Total Loss: 1.438\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.697 0.242 0.053]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.064 0.063 0.825 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.049 0.13  0.734 0.086]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.048 0.074 0.308 0.571]\n",
      "\n",
      "Epoch 67/100, Total Loss: 1.423\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.701 0.239 0.053]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.064 0.061 0.827 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.048 0.129 0.737 0.086]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.047 0.073 0.307 0.573]\n",
      "\n",
      "Epoch 68/100, Total Loss: 1.408\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.704 0.235 0.052]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.063 0.06  0.829 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.048 0.127 0.74  0.086]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.047 0.072 0.307 0.575]\n",
      "\n",
      "Epoch 69/100, Total Loss: 1.394\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.708 0.232 0.052]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.063 0.059 0.83  0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.047 0.125 0.742 0.086]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.046 0.071 0.306 0.577]\n",
      "\n",
      "Epoch 70/100, Total Loss: 1.380\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.008 0.712 0.229 0.052]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.062 0.058 0.832 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.047 0.123 0.745 0.085]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.046 0.07  0.305 0.579]\n",
      "\n",
      "Epoch 71/100, Total Loss: 1.366\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.715 0.226 0.051]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.061 0.057 0.833 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.046 0.122 0.747 0.085]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.045 0.069 0.304 0.581]\n",
      "\n",
      "Epoch 72/100, Total Loss: 1.352\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.718 0.223 0.051]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.061 0.057 0.835 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.046 0.12  0.749 0.085]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.045 0.068 0.304 0.583]\n",
      "\n",
      "Epoch 73/100, Total Loss: 1.339\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.722 0.22  0.051]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.06  0.056 0.836 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.046 0.118 0.752 0.085]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.045 0.067 0.303 0.585]\n",
      "\n",
      "Epoch 74/100, Total Loss: 1.326\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.725 0.217 0.05 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.06  0.055 0.837 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.045 0.117 0.754 0.084]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.044 0.066 0.302 0.587]\n",
      "\n",
      "Epoch 75/100, Total Loss: 1.313\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.728 0.214 0.05 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.059 0.054 0.839 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.045 0.115 0.756 0.084]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.044 0.066 0.301 0.589]\n",
      "\n",
      "Epoch 76/100, Total Loss: 1.301\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.732 0.212 0.05 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.058 0.053 0.84  0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.044 0.113 0.759 0.084]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.043 0.065 0.3   0.592]\n",
      "\n",
      "Epoch 77/100, Total Loss: 1.288\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.735 0.209 0.05 ]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.058 0.052 0.841 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.044 0.112 0.761 0.084]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.043 0.064 0.299 0.594]\n",
      "\n",
      "Epoch 78/100, Total Loss: 1.276\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.738 0.206 0.049]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.057 0.051 0.843 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.043 0.11  0.763 0.083]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.043 0.063 0.298 0.596]\n",
      "\n",
      "Epoch 79/100, Total Loss: 1.264\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.741 0.204 0.049]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.057 0.051 0.844 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.043 0.109 0.765 0.083]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.042 0.062 0.297 0.598]\n",
      "\n",
      "Epoch 80/100, Total Loss: 1.252\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.744 0.201 0.049]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.056 0.05  0.845 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.043 0.107 0.767 0.083]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.042 0.062 0.296 0.6  ]\n",
      "\n",
      "Epoch 81/100, Total Loss: 1.241\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.746 0.199 0.048]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.056 0.049 0.846 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.042 0.106 0.769 0.083]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.041 0.061 0.295 0.602]\n",
      "\n",
      "Epoch 82/100, Total Loss: 1.230\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.749 0.196 0.048]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.055 0.048 0.847 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.042 0.104 0.771 0.083]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.041 0.06  0.294 0.604]\n",
      "\n",
      "Epoch 83/100, Total Loss: 1.219\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.752 0.194 0.048]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.055 0.048 0.848 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.041 0.103 0.773 0.083]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.041 0.06  0.293 0.606]\n",
      "\n",
      "Epoch 84/100, Total Loss: 1.208\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.755 0.192 0.047]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.054 0.047 0.85  0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.041 0.102 0.775 0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.04  0.059 0.292 0.608]\n",
      "\n",
      "Epoch 85/100, Total Loss: 1.197\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.757 0.189 0.047]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.054 0.046 0.851 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.041 0.1   0.777 0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.04  0.058 0.291 0.61 ]\n",
      "\n",
      "Epoch 86/100, Total Loss: 1.186\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.76  0.187 0.047]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.053 0.046 0.852 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.04  0.099 0.778 0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.04  0.058 0.29  0.612]\n",
      "\n",
      "Epoch 87/100, Total Loss: 1.176\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.762 0.185 0.047]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.053 0.045 0.853 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.04  0.098 0.78  0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.039 0.057 0.289 0.614]\n",
      "\n",
      "Epoch 88/100, Total Loss: 1.166\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.765 0.183 0.046]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.052 0.045 0.854 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.04  0.096 0.782 0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.039 0.056 0.288 0.616]\n",
      "\n",
      "Epoch 89/100, Total Loss: 1.156\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.767 0.181 0.046]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.052 0.044 0.855 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.039 0.095 0.784 0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.039 0.056 0.287 0.618]\n",
      "\n",
      "Epoch 90/100, Total Loss: 1.146\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.77  0.179 0.046]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.051 0.043 0.856 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.039 0.094 0.786 0.082]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.038 0.055 0.286 0.62 ]\n",
      "\n",
      "Epoch 91/100, Total Loss: 1.136\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.772 0.177 0.045]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.051 0.043 0.856 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.039 0.093 0.787 0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.038 0.055 0.285 0.622]\n",
      "\n",
      "Epoch 92/100, Total Loss: 1.127\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.775 0.175 0.045]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.05  0.042 0.857 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.038 0.091 0.789 0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.038 0.054 0.284 0.624]\n",
      "\n",
      "Epoch 93/100, Total Loss: 1.117\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.777 0.173 0.045]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.05  0.042 0.858 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.038 0.09  0.79  0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.037 0.053 0.283 0.626]\n",
      "\n",
      "Epoch 94/100, Total Loss: 1.108\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.779 0.171 0.045]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.05  0.041 0.859 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.038 0.089 0.792 0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.037 0.053 0.282 0.628]\n",
      "\n",
      "Epoch 95/100, Total Loss: 1.099\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.781 0.169 0.044]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.049 0.041 0.86  0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.037 0.088 0.794 0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.037 0.052 0.28  0.63 ]\n",
      "\n",
      "Epoch 96/100, Total Loss: 1.090\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.006 0.783 0.167 0.044]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.049 0.04  0.861 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.037 0.087 0.795 0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.037 0.052 0.279 0.632]\n",
      "\n",
      "Epoch 97/100, Total Loss: 1.081\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.005 0.786 0.165 0.044]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.048 0.04  0.862 0.05 ]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.037 0.086 0.797 0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.051 0.278 0.634]\n",
      "\n",
      "Epoch 98/100, Total Loss: 1.073\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.005 0.788 0.163 0.044]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.048 0.039 0.862 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.037 0.085 0.798 0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.051 0.277 0.636]\n",
      "\n",
      "Epoch 99/100, Total Loss: 1.064\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.005 0.79  0.162 0.043]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.047 0.039 0.863 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.036 0.084 0.8   0.081]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.036 0.05  0.276 0.638]\n",
      "\n",
      "Epoch 100/100, Total Loss: 1.056\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.005 0.792 0.16  0.043]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.047 0.038 0.864 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.036 0.082 0.801 0.08 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.05  0.275 0.64 ]\n"
     ]
    }
   ],
   "source": [
    "# vanilla\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# One-hot encoded input and target sequences for the word \"hello\"\n",
    "input_sequence = [\n",
    "    [1, 0, 0, 0],  # h\n",
    "    [0, 1, 0, 0],  # e\n",
    "    [0, 0, 1, 0],  # l\n",
    "    [0, 0, 1, 0]   # l\n",
    "]\n",
    "\n",
    "target_sequence = [\n",
    "    [0, 1, 0, 0],  # e (target for h)\n",
    "    [0, 0, 1, 0],  # l (target for e)\n",
    "    [0, 0, 1, 0],  # l (target for l)\n",
    "    [0, 0, 0, 1]   # o (target for l)\n",
    "]\n",
    "\n",
    "# Create a dictionary to map one-hot vectors to letters\n",
    "idx_to_char = {\n",
    "    str([1, 0, 0, 0]): 'h',\n",
    "    str([0, 1, 0, 0]): 'e',\n",
    "    str([0, 0, 1, 0]): 'l',\n",
    "    str([0, 0, 0, 1]): 'o'\n",
    "}\n",
    "\n",
    "# Initialize RNN parameters\n",
    "h_size = 7\n",
    "W_hx = np.random.randn(h_size, 4)  # input to hidden\n",
    "W_yh = np.random.randn(4, h_size)  # hidden to output\n",
    "W_hh = np.random.randn(h_size, h_size)  # hidden to hidden\n",
    "b_h = np.zeros(h_size)  # hidden layer bias\n",
    "b_y = np.zeros(4)       # output layer bias\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Define helper functions\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # numerical stability\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    h = np.zeros(h_size)  # initialize hidden state for each epoch\n",
    "    \n",
    "    # Gradients initialization for accumulating over timesteps\n",
    "    dW_hx = np.zeros_like(W_hx)\n",
    "    dW_hh = np.zeros_like(W_hh)\n",
    "    dW_yh = np.zeros_like(W_yh)\n",
    "    db_h = np.zeros_like(b_h)\n",
    "    db_y = np.zeros_like(b_y)\n",
    "    dh_next = np.zeros_like(h)\n",
    "    \n",
    "    # Forward and backward pass for each timestep\n",
    "    for i in range(len(input_sequence)):\n",
    "        x = np.array(input_sequence[i])\n",
    "        y = np.array(target_sequence[i])\n",
    "        \n",
    "        # Forward pass\n",
    "        a = np.dot(W_hx, x) + np.dot(h, W_hh) + b_h\n",
    "        h = np.tanh(a)\n",
    "        z = np.dot(W_yh, h) + b_y\n",
    "        y_hat = softmax(z)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = -np.sum(y * np.log(y_hat + 1e-7))\n",
    "        total_loss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "        dy = y_hat - y  # derivative of cross-entropy loss w.r.t output\n",
    "        dW_yh += np.outer(dy, h)\n",
    "        db_y += dy\n",
    "\n",
    "        dh = np.dot(dy, W_yh) + dh_next  # gradient for hidden state\n",
    "        db = (1 - h ** 2) * dh           # backprop through tanh activation\n",
    "        \n",
    "        dW_hx += np.outer(db, x)\n",
    "        dW_hh += np.outer(db, h)\n",
    "        db_h += db\n",
    "        \n",
    "        # Pass the gradient to the next timestep\n",
    "        dh_next = np.dot(W_hh, db)\n",
    "        \n",
    "    \n",
    "    # Clip gradients to prevent exploding gradients\n",
    "    for dparam in [dW_hx, dW_hh, dW_yh, db_h, db_y]:\n",
    "        np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "    # Update parameters\n",
    "    W_hx -= learning_rate * dW_hx\n",
    "    W_hh -= learning_rate * dW_hh\n",
    "    W_yh -= learning_rate * dW_yh\n",
    "    b_h -= learning_rate * db_h\n",
    "    b_y -= learning_rate * db_y\n",
    "\n",
    "    # Print total loss and outcome for this epoch\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}, Total Loss: {total_loss:.3f}\")\n",
    "    print(\"Predicted sequence:\")\n",
    "\n",
    "    # Forward pass through the sequence to print predictions\n",
    "    h = np.zeros(h_size)  # reset hidden state for prediction\n",
    "    for i in range(len(input_sequence)):\n",
    "        x = np.array(input_sequence[i])\n",
    "        a = np.dot(W_hx, x) + np.dot(h, W_hh) + b_h\n",
    "        h = np.tanh(a)\n",
    "        z = np.dot(W_yh, h) + b_y\n",
    "        output = softmax(z)\n",
    "        \n",
    "        # Find the character with the highest probability\n",
    "        predicted_char = max(idx_to_char, key=lambda k: output[int(k.strip('[]').split(', ').index('1'))])\n",
    "        print(f\"  Step {i+1}: '{predicted_char}' with probabilities {output.round(3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100, Total Loss: 3.110\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 0, 1, 0]' with probabilities [0.023 0.39  0.52  0.068]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.079 0.217 0.65  0.053]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.108 0.228 0.534 0.13 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.171 0.143 0.325 0.36 ]\n",
      "\n",
      "Epoch 40/100, Total Loss: 2.005\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.012 0.561 0.364 0.063]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.083 0.109 0.759 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.068 0.186 0.642 0.103]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.066 0.111 0.314 0.509]\n",
      "\n",
      "Epoch 60/100, Total Loss: 1.536\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.009 0.672 0.264 0.055]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.068 0.07  0.814 0.048]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.052 0.142 0.717 0.089]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.051 0.08  0.311 0.558]\n",
      "\n",
      "Epoch 80/100, Total Loss: 1.252\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.007 0.744 0.201 0.049]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.056 0.05  0.845 0.049]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.043 0.107 0.767 0.083]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.042 0.062 0.296 0.6  ]\n",
      "\n",
      "Epoch 100/100, Total Loss: 1.056\n",
      "Predicted sequence:\n",
      "  Step 1: '[0, 1, 0, 0]' with probabilities [0.005 0.792 0.16  0.043]\n",
      "  Step 2: '[0, 0, 1, 0]' with probabilities [0.047 0.038 0.864 0.051]\n",
      "  Step 3: '[0, 0, 1, 0]' with probabilities [0.036 0.082 0.801 0.08 ]\n",
      "  Step 4: '[0, 0, 0, 1]' with probabilities [0.035 0.05  0.275 0.64 ]\n"
     ]
    }
   ],
   "source": [
    "# vanilla\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# One-hot encoded input and target sequences for the word \"hello\"\n",
    "input_sequence = [\n",
    "    [1, 0, 0, 0],  # h\n",
    "    [0, 1, 0, 0],  # e\n",
    "    [0, 0, 1, 0],  # l\n",
    "    [0, 0, 1, 0]   # l\n",
    "]\n",
    "\n",
    "target_sequence = [\n",
    "    [0, 1, 0, 0],  # e (target for h)\n",
    "    [0, 0, 1, 0],  # l (target for e)\n",
    "    [0, 0, 1, 0],  # l (target for l)\n",
    "    [0, 0, 0, 1]   # o (target for l)\n",
    "]\n",
    "\n",
    "# Create a dictionary to map one-hot vectors to letters\n",
    "idx_to_char = {\n",
    "    str([1, 0, 0, 0]): 'h',\n",
    "    str([0, 1, 0, 0]): 'e',\n",
    "    str([0, 0, 1, 0]): 'l',\n",
    "    str([0, 0, 0, 1]): 'o'\n",
    "}\n",
    "\n",
    "# Initialize RNN parameters\n",
    "h_size = 7\n",
    "W_hx = np.random.randn(h_size, 4)  # input to hidden\n",
    "W_yh = np.random.randn(4, h_size)  # hidden to output\n",
    "W_hh = np.random.randn(h_size, h_size)  # hidden to hidden\n",
    "b_h = np.zeros(h_size)  # hidden layer bias\n",
    "b_y = np.zeros(4)       # output layer bias\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Define helper functions\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # numerical stability\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    h = np.zeros(h_size)  # initialize hidden state for each epoch\n",
    "    \n",
    "    # Gradients initialization for accumulating over timesteps\n",
    "    dW_hx = np.zeros_like(W_hx)\n",
    "    dW_hh = np.zeros_like(W_hh)\n",
    "    dW_yh = np.zeros_like(W_yh)\n",
    "    db_h = np.zeros_like(b_h)\n",
    "    db_y = np.zeros_like(b_y)\n",
    "    dh_next = np.zeros_like(h)\n",
    "    \n",
    "    # Forward and backward pass for each timestep\n",
    "    for i in range(len(input_sequence)):\n",
    "        x = np.array(input_sequence[i])\n",
    "        y = np.array(target_sequence[i])\n",
    "        \n",
    "        # Forward pass\n",
    "        a = np.dot(W_hx, x) + np.dot(h, W_hh) + b_h\n",
    "        h = np.tanh(a)\n",
    "        z = np.dot(W_yh, h) + b_y\n",
    "        y_hat = softmax(z)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = -np.sum(y * np.log(y_hat + 1e-7))\n",
    "        total_loss += loss\n",
    "\n",
    "        # Backpropagation\n",
    "        dy = y_hat - y  # derivative of cross-entropy loss w.r.t output\n",
    "        dW_yh += np.outer(dy, h)\n",
    "        db_y += dy\n",
    "\n",
    "        dh = np.dot(dy, W_yh) + dh_next  # gradient for hidden state\n",
    "        da = (1 - h ** 2) * dh           # backprop through tanh activation\n",
    "        \n",
    "        dW_hx += np.outer(da, x)\n",
    "        dW_hh += np.outer(da, h)\n",
    "        db_h += da\n",
    "        \n",
    "        # Pass the gradient to the next timestep\n",
    "        dh_next = np.dot(W_hh, da)\n",
    "        \n",
    "    \n",
    "    # Clip gradients to prevent exploding gradients\n",
    "    for dparam in [dW_hx, dW_hh, dW_yh, db_h, db_y]:\n",
    "        np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "    # Update parameters\n",
    "    W_hx -= learning_rate * dW_hx\n",
    "    W_hh -= learning_rate * dW_hh\n",
    "    W_yh -= learning_rate * dW_yh\n",
    "    b_h -= learning_rate * db_h\n",
    "    b_y -= learning_rate * db_y\n",
    "    # Print results for epochs that are multiples of 20\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs}, Total Loss: {total_loss:.3f}\")\n",
    "        print(\"Predicted sequence:\")\n",
    "\n",
    "        # Forward pass through the sequence to print predictions\n",
    "        h = np.zeros(h_size)  # reset hidden state for prediction\n",
    "        for i in range(len(input_sequence)):\n",
    "            x = np.array(input_sequence[i])\n",
    "            a = np.dot(W_hx, x) + np.dot(h, W_hh) + b_h\n",
    "            h = np.tanh(a)\n",
    "            z = np.dot(W_yh, h) + b_y\n",
    "            output = softmax(z)\n",
    "            \n",
    "            # Find the character with the highest probability\n",
    "            predicted_char = max(idx_to_char, key=lambda k: output[int(k.strip('[]').split(', ').index('1'))])\n",
    "            print(f\"  Step {i+1}: '{predicted_char}' with probabilities {output.round(3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "print(dz.shape)\n",
    "print(dh.shape)\n",
    "#print(np.dot(dy, W_yh.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#record relationship between different h_size \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# One-hot encoded input and target sequences for the word \"hello\"\n",
    "input_sequence = [\n",
    "    [1, 0, 0, 0],  # h\n",
    "    [0, 1, 0, 0],  # e\n",
    "    [0, 0, 1, 0],  # l\n",
    "    [0, 0, 1, 0]   # l\n",
    "]\n",
    "\n",
    "target_sequence = [\n",
    "    [0, 1, 0, 0],  # e (target for h)\n",
    "    [0, 0, 1, 0],  # l (target for e)\n",
    "    [0, 0, 1, 0],  # l (target for l)\n",
    "    [0, 0, 0, 1]   # o (target for l)\n",
    "]\n",
    "\n",
    "# Create a dictionary to map one-hot vectors to letters\n",
    "idx_to_char = {\n",
    "    str([1, 0, 0, 0]): 'h',\n",
    "    str([0, 1, 0, 0]): 'e',\n",
    "    str([0, 0, 1, 0]): 'l',\n",
    "    str([0, 0, 0, 1]): 'o'\n",
    "}\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Define helper functions\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # numerical stability\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "# Track losses for each h_size\n",
    "h_size_values = range(1, 17, 3)\n",
    "loss_records = {}\n",
    "\n",
    "# Loop over different h_size values\n",
    "for h_size in h_size_values:\n",
    "    # Initialize RNN parameters for each h_size\n",
    "    W_xh = np.random.randn(4, h_size)  # input to hidden\n",
    "    W_hy = np.random.randn(h_size, 4)  # hidden to output\n",
    "    W_hh = np.random.randn(h_size, h_size)  # hidden to hidden\n",
    "    b_h = np.zeros(h_size)  # hidden layer bias\n",
    "    b_y = np.zeros(4)       # output layer bias\n",
    "\n",
    "    # Track losses for this h_size\n",
    "    epoch_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        h = np.zeros(h_size)  # initialize hidden state for each epoch\n",
    "\n",
    "        # Gradients initialization for accumulating over timesteps\n",
    "        dW_xh = np.zeros_like(W_xh)\n",
    "        dW_hh = np.zeros_like(W_hh)\n",
    "        dW_hy = np.zeros_like(W_hy)\n",
    "        db_h = np.zeros_like(b_h)\n",
    "        db_y = np.zeros_like(b_y)\n",
    "        dh_next = np.zeros_like(h)\n",
    "\n",
    "        # Forward and backward pass for each timestep\n",
    "        for i in range(len(input_sequence)):\n",
    "            x = np.array(input_sequence[i])\n",
    "            target = np.array(target_sequence[i])\n",
    "\n",
    "            # Forward pass\n",
    "            b = np.dot(x, W_xh) + np.dot(h, W_hh) + b_h\n",
    "            h = np.tanh(b)\n",
    "            a = np.dot(h, W_hy) + b_y\n",
    "            output = softmax(a)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = -np.sum(target * np.log(output + 1e-7))\n",
    "            total_loss += loss\n",
    "\n",
    "            # Backpropagation\n",
    "            dy = output - target  # derivative of cross-entropy loss w.r.t output\n",
    "            dW_hy += np.outer(h, dy)\n",
    "            db_y += dy\n",
    "\n",
    "            dh = np.dot(W_hy, dy) + dh_next  # gradient for hidden state\n",
    "            db = (1 - h ** 2) * dh           # backprop through tanh activation\n",
    "\n",
    "            dW_xh += np.outer(x, db)\n",
    "            dW_hh += np.outer(h, db)\n",
    "            db_h += db\n",
    "\n",
    "            # Pass the gradient to the next timestep\n",
    "            dh_next = np.dot(W_hh, db)\n",
    "\n",
    "        # Clip gradients to prevent exploding gradients\n",
    "        for dparam in [dW_xh, dW_hh, dW_hy, db_h, db_y]:\n",
    "            np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "        # Update parameters\n",
    "        W_xh -= learning_rate * dW_xh\n",
    "        W_hh -= learning_rate * dW_hh\n",
    "        W_hy -= learning_rate * dW_hy\n",
    "        b_h -= learning_rate * db_h\n",
    "        b_y -= learning_rate * db_y\n",
    "\n",
    "        # Record the total loss for this epoch\n",
    "        epoch_losses.append(total_loss)\n",
    "\n",
    "    # Store the loss for this h_size in the dictionary\n",
    "    loss_records[h_size] = epoch_losses\n",
    "\n",
    "# Plot the loss over epochs for each h_size\n",
    "for h_size, losses in loss_records.items():\n",
    "    plt.plot(range(1, epochs + 1), losses, label=f\"h_size = {h_size}\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Epochs for Different Hidden Sizes (h_size)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be able to train a multilayer RNN too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (7,4) and (7,) not aligned: 4 (dim 1) != 7 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Pass the gradients to the next timestep\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     dh2_next \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(W_h1h2, dh2_linear)\n\u001b[0;32m--> 102\u001b[0m     dh1_next \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW_xh1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdh1_linear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Clip gradients to prevent exploding gradients\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dparam \u001b[38;5;129;01min\u001b[39;00m [dW_xh1, dW_h1h2, dW_hy, db_h1, db_h2, db_y]:\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (7,4) and (7,) not aligned: 4 (dim 1) != 7 (dim 0)"
     ]
    }
   ],
   "source": [
    "#record relationship between different h_size \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# One-hot encoded input and target sequences for the word \"hello\"\n",
    "input_sequence = [\n",
    "    [1, 0, 0, 0],  # h\n",
    "    [0, 1, 0, 0],  # e\n",
    "    [0, 0, 1, 0],  # l\n",
    "    [0, 0, 1, 0]   # l\n",
    "]\n",
    "\n",
    "target_sequence = [\n",
    "    [0, 1, 0, 0],  # e (target for h)\n",
    "    [0, 0, 1, 0],  # l (target for e)\n",
    "    [0, 0, 1, 0],  # l (target for l)\n",
    "    [0, 0, 0, 1]   # o (target for l)\n",
    "]\n",
    "\n",
    "# Create a dictionary to map one-hot vectors to letters\n",
    "idx_to_char = {\n",
    "    str([1, 0, 0, 0]): 'h',\n",
    "    str([0, 1, 0, 0]): 'e',\n",
    "    str([0, 0, 1, 0]): 'l',\n",
    "    str([0, 0, 0, 1]): 'o'\n",
    "}\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Define helper functions\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # numerical stability\n",
    "    return exp_x / exp_x.sum()\n",
    "\n",
    "# Track losses for each h_size\n",
    "h_size_values = range(1, 17, 3)\n",
    "loss_records = {}\n",
    "\n",
    "# Loop over different h_size values\n",
    "for h_size in h_size_values:\n",
    "    # Initialize RNN parameters for each h_size\n",
    "    W_xh = np.random.randn(4, h_size)  # input to hidden\n",
    "    W_hy = np.random.randn(h_size, 4)  # hidden to output\n",
    "    W_hh = np.random.randn(h_size, h_size)  # hidden to hidden\n",
    "    b_h = np.zeros(h_size)  # hidden layer bias\n",
    "    b_y = np.zeros(4)       # output layer bias\n",
    "\n",
    "    # Track losses for this h_size\n",
    "    epoch_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        h = np.zeros(h_size)  # initialize hidden state for each epoch\n",
    "\n",
    "        # Gradients initialization for accumulating over timesteps\n",
    "        dW_xh = np.zeros_like(W_xh)\n",
    "        dW_hh = np.zeros_like(W_hh)\n",
    "        dW_hy = np.zeros_like(W_hy)\n",
    "        db_h = np.zeros_like(b_h)\n",
    "        db_y = np.zeros_like(b_y)\n",
    "        dh_next = np.zeros_like(h)\n",
    "\n",
    "        # Forward and backward pass for each timestep\n",
    "        for i in range(len(input_sequence)):\n",
    "            x = np.array(input_sequence[i])\n",
    "            target = np.array(target_sequence[i])\n",
    "\n",
    "            # Forward pass\n",
    "            b = np.dot(x, W_xh) + np.dot(h, W_hh) + b_h\n",
    "            h = np.tanh(b)\n",
    "            a = np.dot(h, W_hy) + b_y\n",
    "            output = softmax(a)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = -np.sum(target * np.log(output + 1e-7))\n",
    "            total_loss += loss\n",
    "\n",
    "            # Backpropagation\n",
    "            dy = output - target  # derivative of cross-entropy loss w.r.t output\n",
    "            dW_hy += np.outer(h, dy)\n",
    "            db_y += dy\n",
    "\n",
    "            dh = np.dot(W_hy, dy) + dh_next  # gradient for hidden state\n",
    "            db = (1 - h ** 2) * dh           # backprop through tanh activation\n",
    "\n",
    "            dW_xh += np.outer(x, db)\n",
    "            dW_hh += np.outer(h, db)\n",
    "            db_h += db\n",
    "\n",
    "            # Pass the gradient to the next timestep\n",
    "            dh_next = np.dot(W_hh, db)\n",
    "\n",
    "        # Clip gradients to prevent exploding gradients\n",
    "        for dparam in [dW_xh, dW_hh, dW_hy, db_h, db_y]:\n",
    "            np.clip(dparam, -1, 1, out=dparam)\n",
    "\n",
    "        # Update parameters\n",
    "        W_xh -= learning_rate * dW_xh\n",
    "        W_hh -= learning_rate * dW_hh\n",
    "        W_hy -= learning_rate * dW_hy\n",
    "        b_h -= learning_rate * db_h\n",
    "        b_y -= learning_rate * db_y\n",
    "\n",
    "        # Record the total loss for this epoch\n",
    "        epoch_losses.append(total_loss)\n",
    "\n",
    "    # Store the loss for this h_size in the dictionary\n",
    "    loss_records[h_size] = epoch_losses\n",
    "\n",
    "# Plot the loss over epochs for each h_size\n",
    "for h_size, losses in loss_records.items():\n",
    "    plt.plot(range(1, epochs + 1), losses, label=f\"h_size = {h_size}\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over Epochs for Different Hidden Sizes (h_size)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mensius",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
